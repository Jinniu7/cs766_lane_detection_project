{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import os, glob\n",
    "import numpy as np\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from scipy import stats\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def Main():\n",
    "    # Note 1: need to manually label (i.e. create masks for yellow lane vs. road and white lane vs. road) \n",
    "    # for first k frames.\n",
    "    k = 10\n",
    "    \n",
    "    # Note 2: need to edit file names for data (RGB images = rgbImage+num.jpg, mask = 'mask'+color+'Img'+num.jpg)\n",
    "    \n",
    "    # read in previous k images (EDIT PATH)\n",
    "    listOfAllImages = [plt.imread(path) for path in glob.glob('laneData/rgbImage*.jpg')]\n",
    "    frames = listOfAllImages[0:k]\n",
    "    \n",
    "    # read in previous k masks (EDIT PATH)\n",
    "    # note: these masks will be binary (0,1) 1 => lane, 0 => road\n",
    "    listOfAllYellowMasks = [plt.imread(path) for path in glob.glob('laneData/maskYellowImg*.jpg')]\n",
    "    imageYellowMasks = listOfAllYellowMasks[0:k]\n",
    "    listOfAllWhiteMasks = [plt.imread(path) for path in glob.glob('laneData/maskWhiteImg*.jpg')]\n",
    "    imageWhiteMasks = listOfAllWhiteMasks[0:k]\n",
    "       \n",
    "    currIdx = 0    \n",
    "    for img in frames:\n",
    "        # remove everything above vanishing point?\n",
    "        \n",
    "        # find w_max for yellow and white lanes\n",
    "        w_yellow, w_white = findW(frames, imageYellowMasks, imageWhiteMasks)\n",
    "        \n",
    "        # apply weights to current image\n",
    "        grayImg_yellow = convertToGray(w_yellow, img)\n",
    "        grayImg_white = convertToGray(w_white, img)\n",
    "        \n",
    "        # compute mean of lane vs. road for each yellow and white lanes\n",
    "        m_l_y\n",
    "        m_r_y\n",
    "        m_l_w\n",
    "        m_r_w\n",
    "        d_y\n",
    "        d_w\n",
    "        \n",
    "        # apply adaptive canny edge\n",
    "        canny_y = adaptiveCanny(w_yellow, m_l_y, m_r_y, d_y, grayImg_yellow)\n",
    "        canny_w = adaptiveCanny(w_white, m_l_w, m_r_w, d_w, grayImg_white)\n",
    "        \n",
    "        # combine both images with OR operation\n",
    "        combined_img = cv2.bitwise_or(canny_y, canny_w)\n",
    "        \n",
    "        # HT\n",
    "        ht = cv2.HoughLinesP(combined_img, rho=1, theta=np.pi/180, threshold=20, minLineLength=20, maxLineGap=300)\n",
    "        \n",
    "        # ROI\n",
    "        \n",
    "        # Curve-fit\n",
    "        \n",
    "        # increment k and update frames and masks\n",
    "        currIdx = currIdx + 1\n",
    "        k = k + 1\n",
    "        frames = listOfAllImages[currIdx:k]\n",
    "        imageYellowMasks = imageYellowMasks[currIdx:k]\n",
    "        imageWhiteMasks = imageWhiteMasks[currIdx:k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def findW(frames, imageYellowMasks, imageWhiteMasks):\n",
    "    colors = ['Yellow', 'White']\n",
    "    \n",
    "    w_yellow = []\n",
    "    w_white = []\n",
    "    \n",
    "    for c in colors:\n",
    "        # create training data\n",
    "        X, y = createTrainingData(frames, \"image{}Masks\".format(c).replace(\"'\",\"\"))\n",
    "        \n",
    "        # compute gradient-enhancing vectors\n",
    "        w_max = applyLDA(X, y)\n",
    "        \n",
    "        if c == 'Yellow':\n",
    "            w_yellow = w_max\n",
    "        else:\n",
    "            w_white = w_max\n",
    "        \n",
    "    return w_yellow, w_white\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this function creates the training data for class c for frame t.\n",
    "# k = number of previous frames (default set arbitrarily to 10)\n",
    "# list_of_RGB_Images = input images\n",
    "# imagesMasks = correspond to either yellow lane vs. road or white lane vs. road\n",
    "def createTrainingData(list_of_RGB_Images, imageMasks):\n",
    "    # Create a list of all RGB values\n",
    "    R = []\n",
    "    G = []\n",
    "    B = []\n",
    "    for img in list_of_RGB_Images:\n",
    "        # reshape each color val into an array\n",
    "        currR = img[:,:,0].reshape(np.shape(img[:,:,0])[0]*np.shape(img[:,:,0])[1]) \n",
    "        currG = img[:,:,1].reshape(np.shape(img[:,:,1])[0]*np.shape(img[:,:,1])[1])\n",
    "        currB = img[:,:,2].reshape(np.shape(img[:,:,2])[0]*np.shape(img[:,:,2])[1])\n",
    "        \n",
    "        # concatenate with R, G, and B\n",
    "        R = np.concatenate((R, currR))\n",
    "        G = np.concatenate((G, currG))\n",
    "        B = np.concatenate((B, currB))\n",
    "        \n",
    "    y = []\n",
    "    for mask in imageMasks:\n",
    "        currY = mask.reshape(np.shape(mask)[0]*np.shape(mask)[1]) \n",
    "        y = np.concatenaute((y, currY))\n",
    "        \n",
    "    # create training data to return shape(num total pixels, 3(R,G,B))\n",
    "    X = np.zeros((len(R), 3))\n",
    "    X[:,0] = R\n",
    "    X[:,1] = G\n",
    "    X[:,2] = B\n",
    "\n",
    "    return X, y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# this function fits data using LDA to find conversion vector from previous images (X,y)\n",
    "# then applies learned weights to current image (currImage)\n",
    "def applyLDA(X, y):\n",
    "    # create classifier object\n",
    "    clf = LinearDiscriminantAnalysis()\n",
    "\n",
    "    # fit classifier to data\n",
    "    clf.fit(X, y)\n",
    "    \n",
    "    # return learned weights (i.e. the gradient-enhancing conversion vector)\n",
    "    return clf.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# this function converts an image with the calculated gradient-enhancing vector\n",
    "def convertToGray(w, img):\n",
    "    grayImg = (w[0]*img[:,:,0] + w[1]*img[:,:,1] + w[2]*img[:,:,2]).astype(np.uint8)\n",
    "    return grayImg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# this function computes two threshold values to determine edges\n",
    "def adaptiveCanny(w, m_l, m_r, d, image):\n",
    "    th_L = abs(np.dot(w, m_l) - np.dot(w, m_r))\n",
    "    th_S = max(abs(np.dot(w, m_l) - d), abs(np.dot(w, m_r) - d))\n",
    "    \n",
    "    return cv2.Canny(image, th_S, th_L)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
